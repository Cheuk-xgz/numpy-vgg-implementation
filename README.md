# numpy-vgg-implementation
# Mini-VGG from Scratch

## 前
本项目由初学者实践分享，详情请见源码有非常详细的注解内容。仅做教学用途，不可直接用于生产。模型会持续进行优化分享，也欢迎各位前辈指正错误，贡献良策

## 概述
本项目是一个**完全从零实现**的简化版VGG网络，使用纯NumPy编写，**不依赖PyTorch、TensorFlow等深度学习框架**。通过手动实现卷积层、池化层、全连接层的前向传播和反向传播，深入理解卷积神经网络（CNN）的底层原理。

- **深入理解**：摆脱框架黑盒，从数学公式到代码实现
- **教学价值**：详细的注释和数学推导，适合初学者学习

### 完整实现
- **卷积层 (Conv2D)**：3×3卷积核，支持padding和stride
- **激活函数 (ReLU)**：非线性激活，包含前向/反向传播
- **最大池化 (MaxPool2D)**：2×2池化窗口，支持梯度回传
- **全连接层 (Linear)**：完整的矩阵乘法实现
- **展平层 (Flatten)**：多维特征图转一维向量
- **Dropout层**：训练时随机失活，防止过拟合

### 核心功能
- **前向传播**：完整的网络前向计算流程
- **反向传播**：基于链式法则的手动梯度计算
- **损失函数**：交叉熵损失（带数值稳定性处理）
- **优化器**：随机梯度下降（SGD）参数更新
- **梯度裁剪**：防止梯度爆炸


### 与完整VGG16对比
| 特性 | 完整VGG16 | 本项目 | 说明 |
|------|-----------|--------|------|
| 卷积层数 | 13层 | 2层 | 简化用于教学 |
| 参数数量 | 1.38亿 | ~10万 | 大幅减少 |
| 输入尺寸 | 224×224 | 32×32 | 适应合成数据 |
| 全连接层 | 3层 | 2层 | 保持基本结构 |
| 核心思想 | 相同 | 相同 | 3×3卷积、ReLU、池化 |


### 环境要求
- Python 3.8+
- NumPy 1.21+

### 实现

# 1. 克隆仓库
git clone https://github.com/yourusername/mini-vgg-from-scratch.git
cd mini-vgg-from-scratch

# 2. 安装依赖（只需要NumPy）
pip install numpy

# 3. 运行结果示例
生成数据...
创建模型...
开始训练...
- Epoch  1/10: Loss=2.3347, Val Accuracy=0.0733
- Epoch  2/10: Loss=2.3115, Val Accuracy=0.0867
- Epoch  3/10: Loss=2.3084, Val Accuracy=0.1067
- Epoch  4/10: Loss=2.2985, Val Accuracy=0.1067
- Epoch  5/10: Loss=2.3003, Val Accuracy=0.1267
- Epoch  6/10: Loss=2.2905, Val Accuracy=0.1267
- Epoch  7/10: Loss=2.2876, Val Accuracy=0.1133
- Epoch  8/10: Loss=2.2775, Val Accuracy=0.1000
- Epoch  9/10: Loss=2.2783, Val Accuracy=0.1000
- Epoch 10/10: Loss=2.2747, Val Accuracy=0.0933

最终测试准确率: 16.67%

最佳验证准确率: 12.67%

进程已结束，退出代码为 0

注：16%的准确率对于这个简化模型是正常的。完整VGG16在ImageNet上达到70%+准确率，但使用了13层卷积、数百万标注图像等资源
本项目数据体量较小，可直接本地训练（mac air m4 本地运行时间约20min）

# 4. 改进
- 为做演示，本项目的训练数据由ai生成模拟数据集，总数据只有1000，可尝试接入自备数据集
- 时间问题，训练轮数仅10轮，可适当增加
- 非完整vgg网络（本项目仅2层），可自行添加层数
- 。。。。



